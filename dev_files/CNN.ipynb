{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "711adebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83de885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.0      36.6      36.7      38.0      38.2  38.300000000000004  \\\n",
      "0   3.0074   81.2963   83.7169  119.6888  115.8881            413.4768   \n",
      "1  13.6523  361.5547  119.7225  170.9554   84.0531            273.8909   \n",
      "2   7.1155   80.2869  169.7490  149.4092  132.8215            198.8544   \n",
      "3   2.0998  235.5117  161.2402  241.3578  243.2237             89.7297   \n",
      "4  16.2152  384.2739  174.5714   84.3117  137.9726            261.8213   \n",
      "\n",
      "       39.0      39.1      39.2       39.6  ...    466.0    523.0    523.1  \\\n",
      "0  136.8640  817.5328   86.4743   477.6116  ...  15.8853   1.5231   4.9432   \n",
      "1  175.9083  665.0791  588.2624    84.1962  ...   6.9459  26.9344   9.0805   \n",
      "2  150.5273  112.4005  335.4482   675.7621  ...   9.3406  18.8055   7.0021   \n",
      "3  640.7394  121.9373  396.3036  1138.3905  ...  26.2306   8.1640  26.6106   \n",
      "4  365.8102   96.3555  219.9515   211.2868  ...  39.9084   4.7010  50.1098   \n",
      "\n",
      "     523.4     524.4    524.5     554.2     554.4    1046.0       target  \n",
      "0   9.2590   20.5432   8.0715   23.6439   15.2647   34.3166   [E, major]  \n",
      "1  11.1132    6.9261  17.8961   25.1414   32.0681   11.3592   [E, major]  \n",
      "2  11.4548   11.9478  21.4284   23.2868   25.3144   10.5996   [E, major]  \n",
      "3  15.5312   17.1421  17.1426   28.0372   25.6042   18.4512   [E, major]  \n",
      "4  37.2416  113.0849  70.5330  144.2466  171.6769  106.9502  [C#, major]  \n",
      "\n",
      "[5 rows x 1001 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reading in File . . .\n",
    "file_path = \"train.json\"\n",
    "json_data = []\n",
    "\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "773550bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining targets that are tonally equivalent . . .   \n",
    "    \n",
    "def combine_equal(df):\n",
    "    tonal_equ = {\n",
    "                \"A#\": \"Bb\",\n",
    "                \"B#\": \"C\",\n",
    "                \"C#\": \"Db\",\n",
    "                \"D#\": \"Eb\",\n",
    "                \"E#\": \"F\",\n",
    "                \"F#\": \"Gb\",\n",
    "                \"G#\": \"Ab\"\n",
    "            }\n",
    "    \n",
    "    df[['note', 'modality']] = pd.DataFrame(df.target.tolist(), index=df.index)\n",
    "    df[\"note\"] = df['note'].replace(tonal_equ)\n",
    "    df[\"target\"] = df[[\"note\", \"modality\"]].astype(str).apply(' '.join, axis=1)\n",
    "    df.drop([\"note\", \"modality\"], axis=1, inplace=True)\n",
    "\n",
    "combine_equal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0f87e732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0.0      36.6      36.7      38.0      38.2  38.300000000000004  \\\n",
      "0 -0.028187 -0.099215 -0.037191 -0.118219 -0.108142           -0.120322   \n",
      "1 -0.028186 -0.099127 -0.037188 -0.118203 -0.108152           -0.120366   \n",
      "2 -0.028187 -0.099215 -0.037183 -0.118209 -0.108137           -0.120389   \n",
      "3 -0.028188 -0.099167 -0.037184 -0.118181 -0.108105           -0.120424   \n",
      "4 -0.028186 -0.099120 -0.037183 -0.118230 -0.108136           -0.120370   \n",
      "\n",
      "       39.0      39.1      39.2      39.6  ...     466.0     523.0     523.1  \\\n",
      "0 -0.125820 -0.115750 -0.114163 -0.118979  ... -0.139936 -0.177052 -0.184882   \n",
      "1 -0.125809 -0.115793 -0.114020 -0.119089  ... -0.139938 -0.177044 -0.184881   \n",
      "2 -0.125816 -0.115949 -0.114092 -0.118923  ... -0.139938 -0.177047 -0.184881   \n",
      "3 -0.125672 -0.115947 -0.114075 -0.118794  ... -0.139933 -0.177050 -0.184875   \n",
      "4 -0.125753 -0.115954 -0.114125 -0.119053  ... -0.139929 -0.177051 -0.184868   \n",
      "\n",
      "      523.4     524.4     524.5     554.2     554.4    1046.0    target  \n",
      "0 -0.179772 -0.173681 -0.170679 -0.125768 -0.136611 -0.090960   E major  \n",
      "1 -0.179772 -0.173685 -0.170676 -0.125767 -0.136605 -0.090967   E major  \n",
      "2 -0.179772 -0.173684 -0.170675 -0.125768 -0.136607 -0.090967   E major  \n",
      "3 -0.179770 -0.173682 -0.170676 -0.125766 -0.136607 -0.090965   E major  \n",
      "4 -0.179764 -0.173653 -0.170660 -0.125730 -0.136561 -0.090938  Db major  \n",
      "\n",
      "[5 rows x 1001 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing using z-score standardization method . . .\n",
    "\n",
    "target_column = df['target']\n",
    "features = df.select_dtypes(include=[np.number])\n",
    "normalized_features = (features - features.mean()) / features.std()\n",
    "df_normalized = pd.concat([normalized_features, target_column], axis=1)\n",
    "print(df_normalized.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "20c76756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        E major\n",
      "1        E major\n",
      "2        E major\n",
      "3        E major\n",
      "4       Db major\n",
      "          ...   \n",
      "9842     C major\n",
      "9843    Ab major\n",
      "9844    Gb minor\n",
      "9845    Ab major\n",
      "9846     D minor\n",
      "Name: target, Length: 9847, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# function to randomly drop features to make data into perfect square for CNN input . . .\n",
    "\n",
    "def reduce_to_perfect_square(df):\n",
    "    \n",
    "    num_features = df.shape[1]\n",
    "    max_square = int(np.sqrt(num_features)) ** 2\n",
    "    \n",
    "    if max_square == num_features:\n",
    "        return df\n",
    "    else:\n",
    "        features_to_drop = num_features - max_square-1\n",
    "        dropped_features = np.random.choice(df.columns, size=features_to_drop, replace=False)\n",
    "        reduced_df = df.drop(columns=dropped_features)\n",
    "        \n",
    "        return reduced_df\n",
    "\n",
    "reduced_df = reduce_to_perfect_square(df_normalized)\n",
    "print(reduced_df[\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4f2f7d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "#zero padding? to achieve a 32 by 32 image . . . (previously only 31 features, with more features use more)\n",
    "\n",
    "unique_classes = reduced_df['target'].nunique()\n",
    "print(unique_classes)\n",
    "# padding = np.zeros((reduced_df.shape[0], 1))\n",
    "# df_padded = pd.concat([reduced_df, pd.DataFrame(padding, columns=['Pad'+str(i) for i in range(1)])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "177d1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the data into the image size . . . will need to change for larger sets\n",
    "X = reduced_df.drop('target', axis=1).values\n",
    "X_reshaped = X.reshape(-1, 31, 31, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b9cf2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train test validation sets\n",
    "label_encoder = LabelEncoder()\n",
    "reduced_df['target_encoded'] = label_encoder.fit_transform(reduced_df['target'])\n",
    "y = reduced_df['target_encoded'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b8ffb4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxsivry/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,600</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m51,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │        \u001b[38;5;34m24,600\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">278,136</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m278,136\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">278,136</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m278,136\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining the CNN architecture . . .\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(12, 12), strides=(2, 2), activation='relu', input_shape=(31, 31, 1)),\n",
    "    layers.Conv2D(64, kernel_size=(5, 5), strides=(1, 2), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(len(np.unique(df['target'])), activation='softmax')\n",
    "])\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.05,\n",
    "    decay_steps=2000,\n",
    "    decay_rate=0.95,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f26955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.0702 - loss: 21.7603 - val_accuracy: 0.0584 - val_loss: 3.1332\n",
      "Epoch 2/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.0728 - loss: 3.0982 - val_accuracy: 0.0716 - val_loss: 3.1185\n",
      "Epoch 3/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.0665 - loss: 3.1084 - val_accuracy: 0.0584 - val_loss: 3.1186\n",
      "Epoch 4/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.0664 - loss: 3.1058 - val_accuracy: 0.0741 - val_loss: 3.1286\n",
      "Epoch 5/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.0785 - loss: 3.1091 - val_accuracy: 0.0594 - val_loss: 3.1263\n",
      "Epoch 6/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.0742 - loss: 3.1037 - val_accuracy: 0.0741 - val_loss: 3.1193\n",
      "Epoch 7/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.0704 - loss: 3.1015 - val_accuracy: 0.0741 - val_loss: 3.1239\n",
      "Epoch 8/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.0724 - loss: 3.1025 - val_accuracy: 0.0716 - val_loss: 3.1311\n",
      "Epoch 9/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.0753 - loss: 3.1018 - val_accuracy: 0.0584 - val_loss: 3.1242\n",
      "Epoch 10/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.0777 - loss: 3.1054 - val_accuracy: 0.0741 - val_loss: 3.1242\n",
      "Epoch 11/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.0694 - loss: 3.1038 - val_accuracy: 0.0584 - val_loss: 3.1207\n",
      "Epoch 12/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.0708 - loss: 3.1032 - val_accuracy: 0.0594 - val_loss: 3.1232\n",
      "Epoch 13/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.0742 - loss: 3.1031 - val_accuracy: 0.0558 - val_loss: 3.1208\n",
      "Epoch 14/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0771 - loss: 3.0995 - val_accuracy: 0.0579 - val_loss: 3.1166\n",
      "Epoch 15/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.0740 - loss: 3.1024 - val_accuracy: 0.0741 - val_loss: 3.1239\n",
      "Epoch 16/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0754 - loss: 3.1023 - val_accuracy: 0.0741 - val_loss: 3.1226\n",
      "Epoch 17/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.0679 - loss: 3.1060 - val_accuracy: 0.0741 - val_loss: 3.1182\n",
      "Epoch 18/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0760 - loss: 3.1114 - val_accuracy: 0.0594 - val_loss: 3.1213\n",
      "Epoch 19/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0746 - loss: 3.0971 - val_accuracy: 0.0741 - val_loss: 3.1174\n",
      "Epoch 20/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.0741 - loss: 3.0987 - val_accuracy: 0.0741 - val_loss: 3.1208\n",
      "Epoch 21/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0693 - loss: 3.1078 - val_accuracy: 0.0584 - val_loss: 3.1207\n",
      "Epoch 22/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0681 - loss: 3.1031 - val_accuracy: 0.0741 - val_loss: 3.1237\n",
      "Epoch 23/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0752 - loss: 3.1025 - val_accuracy: 0.0741 - val_loss: 3.1214\n",
      "Epoch 24/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0721 - loss: 3.1044 - val_accuracy: 0.0584 - val_loss: 3.1204\n",
      "Epoch 25/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0764 - loss: 3.1026 - val_accuracy: 0.0741 - val_loss: 3.1322\n",
      "Epoch 26/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0717 - loss: 3.0976 - val_accuracy: 0.0716 - val_loss: 3.1242\n",
      "Epoch 27/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.0667 - loss: 3.1098 - val_accuracy: 0.0741 - val_loss: 3.1124\n",
      "Epoch 28/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0709 - loss: 3.1024 - val_accuracy: 0.0594 - val_loss: 3.1234\n",
      "Epoch 29/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0742 - loss: 3.1067 - val_accuracy: 0.0584 - val_loss: 3.1204\n",
      "Epoch 30/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.0762 - loss: 3.1019 - val_accuracy: 0.0594 - val_loss: 3.1265\n",
      "Epoch 31/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0710 - loss: 3.1038 - val_accuracy: 0.0594 - val_loss: 3.1233\n",
      "Epoch 32/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0760 - loss: 3.1013 - val_accuracy: 0.0741 - val_loss: 3.1226\n",
      "Epoch 33/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.0805 - loss: 3.0947 - val_accuracy: 0.0584 - val_loss: 3.1199\n",
      "Epoch 34/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.0787 - loss: 3.0906 - val_accuracy: 0.0594 - val_loss: 3.1242\n",
      "Epoch 35/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.0699 - loss: 3.0951 - val_accuracy: 0.0741 - val_loss: 3.1276\n",
      "Epoch 36/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.0787 - loss: 3.0959 - val_accuracy: 0.0741 - val_loss: 3.1197\n",
      "Epoch 37/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.0716 - loss: 3.1052 - val_accuracy: 0.0741 - val_loss: 3.1182\n",
      "Epoch 38/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.0614 - loss: 3.1034 - val_accuracy: 0.0741 - val_loss: 3.1227\n",
      "Epoch 39/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0744 - loss: 3.1040 - val_accuracy: 0.0741 - val_loss: 3.1324\n",
      "Epoch 40/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0644 - loss: 3.1078 - val_accuracy: 0.0741 - val_loss: 3.1265\n",
      "Epoch 41/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0786 - loss: 3.1011 - val_accuracy: 0.0741 - val_loss: 3.1181\n",
      "Epoch 42/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.0788 - loss: 3.0932 - val_accuracy: 0.0741 - val_loss: 3.1160\n",
      "Epoch 43/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.0635 - loss: 3.1021 - val_accuracy: 0.0741 - val_loss: 3.1242\n",
      "Epoch 44/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0780 - loss: 3.1021 - val_accuracy: 0.0741 - val_loss: 3.1173\n",
      "Epoch 45/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.0810 - loss: 3.1031 - val_accuracy: 0.0594 - val_loss: 3.1214\n",
      "Epoch 46/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0715 - loss: 3.1068 - val_accuracy: 0.0594 - val_loss: 3.1201\n",
      "Epoch 47/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.0676 - loss: 3.1103 - val_accuracy: 0.0741 - val_loss: 3.1162\n",
      "Epoch 48/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0797 - loss: 3.1034 - val_accuracy: 0.0741 - val_loss: 3.1171\n",
      "Epoch 49/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0796 - loss: 3.0976 - val_accuracy: 0.0741 - val_loss: 3.1224\n",
      "Epoch 50/50\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0734 - loss: 3.0993 - val_accuracy: 0.0741 - val_loss: 3.1186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0749 - loss: 3.1162\n",
      "Validation Loss: 3.118629217147827, Validation Accuracy: 0.07411167770624161\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "performance = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {performance[0]}, Validation Accuracy: {performance[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
