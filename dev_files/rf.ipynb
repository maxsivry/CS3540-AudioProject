{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0308bd-ba09-4b56-bd6e-c8bd35fb165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094669f1-8f99-49e7-b693-ac6097f699c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_41092\\892108931.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df = pd.read_json(file_path, lines=True)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_41092\\892108931.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df = pd.read_json(file_path, lines=True)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_41092\\892108931.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df = pd.read_json(file_path, lines=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.0      36.6      36.7      38.0      38.2  38.300000000000004  \\\n",
      "0   3.0074   81.2963   83.7169  119.6888  115.8881            413.4768   \n",
      "1  13.6523  361.5547  119.7225  170.9554   84.0531            273.8909   \n",
      "2   7.1155   80.2869  169.7490  149.4092  132.8215            198.8544   \n",
      "3   2.0998  235.5117  161.2402  241.3578  243.2237             89.7297   \n",
      "4  16.2152  384.2739  174.5714   84.3117  137.9726            261.8213   \n",
      "\n",
      "       39.0      39.1      39.2       39.6  ...    466.0    523.0    523.1  \\\n",
      "0  136.8640  817.5328   86.4743   477.6116  ...  15.8853   1.5231   4.9432   \n",
      "1  175.9083  665.0791  588.2624    84.1962  ...   6.9459  26.9344   9.0805   \n",
      "2  150.5273  112.4005  335.4482   675.7621  ...   9.3406  18.8055   7.0021   \n",
      "3  640.7394  121.9373  396.3036  1138.3905  ...  26.2306   8.1640  26.6106   \n",
      "4  365.8102   96.3555  219.9515   211.2868  ...  39.9084   4.7010  50.1098   \n",
      "\n",
      "     523.4     524.4    524.5     554.2     554.4    1046.0       target  \n",
      "0   9.2590   20.5432   8.0715   23.6439   15.2647   34.3166   [E, major]  \n",
      "1  11.1132    6.9261  17.8961   25.1414   32.0681   11.3592   [E, major]  \n",
      "2  11.4548   11.9478  21.4284   23.2868   25.3144   10.5996   [E, major]  \n",
      "3  15.5312   17.1421  17.1426   28.0372   25.6042   18.4512   [E, major]  \n",
      "4  37.2416  113.0849  70.5330  144.2466  171.6769  106.9502  [C#, major]  \n",
      "\n",
      "[5 rows x 1001 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reading in File . . .\n",
    "file_path = \"train.json\"\n",
    "json_data = []\n",
    "\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3b91e7-fb0b-4bba-b0e8-7920532b5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining targets that are tonally equivalent . . .   \n",
    "    \n",
    "def combine_equal(df):\n",
    "    tonal_equ = {\n",
    "                \"A#\": \"Bb\",\n",
    "                \"B#\": \"C\",\n",
    "                \"C#\": \"Db\",\n",
    "                \"D#\": \"Eb\",\n",
    "                \"E#\": \"F\",\n",
    "                \"F#\": \"Gb\",\n",
    "                \"G#\": \"Ab\"\n",
    "            }\n",
    "    \n",
    "    df[['note', 'modality']] = pd.DataFrame(df.target.tolist(), index=df.index)\n",
    "    df[\"note\"] = df['note'].replace(tonal_equ)\n",
    "    df[\"target\"] = df[[\"note\", \"modality\"]].astype(str).apply(' '.join, axis=1)\n",
    "    df.drop([\"note\", \"modality\"], axis=1, inplace=True)\n",
    "\n",
    "combine_equal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd73a17-643b-4901-a437-c9efb3b529a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training x: (7877, 1000) y: (7877,)\n",
      "Testing x: (1970, 1000) y: (1970,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.3821,   0.497 ,   0.7169, ...,   4.9492,   0.896 ,   3.2916],\n",
       "       [ 16.4461,  55.8946,  54.2504, ..., 163.5266, 155.7604,  10.2477],\n",
       "       [  5.2831,   7.8013,   9.3183, ..., 104.2608, 134.1521,  32.3494],\n",
       "       ...,\n",
       "       [  5.6634,  25.6487,  38.779 , ...,  50.1856,  43.7502, 206.6477],\n",
       "       [ 31.726 ,   7.6548,  39.6652, ..., 162.1529, 186.4395,  19.2206],\n",
       "       [  0.3202, 169.3784,  94.1028, ...,  57.3187,  35.3127,  13.3427]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting into train test validation sets\n",
    "X = df.drop('target', axis=1).values\n",
    "label_encoder = LabelEncoder()\n",
    "df['target_encoded'] = label_encoder.fit_transform(df['target'])\n",
    "y = df['target_encoded'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Testing function for the data split\n",
    "\n",
    "print(\"Training x:\", x_train.shape,\"y:\", y_train.shape)\n",
    "print(\"Testing x:\", x_test.shape,\"y:\", y_test.shape)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb333080-a3a3-42e7-bf95-9ea4d7bdde98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23147208121827412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing decision tree\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "score = clf.score(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6172ed96-6994-4396-882a-5da650a59c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172588832487309"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "cls = RandomForestClassifier()\n",
    "cls.fit(x_train, y_train)\n",
    "\n",
    "score = cls.score(x_test, y_test)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
