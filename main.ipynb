{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project: Key Detection\n",
    "Authors: Zach Hayes, Matt Gaetano, Max Ivry\n",
    "\n",
    "Course: CS3540\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Feature Engineering Pipeline\n",
    "Data cleaning occured earlier in process. See clean.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_audio(df, n_audio_features) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    'Join' the existing dataframe with the audio files via\n",
    "    mapping to frequency features.\n",
    "    \"\"\"\n",
    "    # Determine the size for all instances (largest number of samples)\n",
    "    longest = 0\n",
    "    rate = 0\n",
    "    locations = df[\"location\"].to_numpy()\n",
    "    for loc in locations:\n",
    "        path = \"dataset/\" + loc\n",
    "        rate, data = wavfile.read(path)\n",
    "        length = len(data)\n",
    "        if length > longest:\n",
    "            longest = length\n",
    "\n",
    "    freq_bins = rfftfreq(longest, 1 / rate)\n",
    "\n",
    "    # Calculate the features to populate a data array\n",
    "    bundles = []\n",
    "    bundle = None\n",
    "    for loc in locations:\n",
    "        path = \"dataset/\" + loc\n",
    "        samplerate, data = wavfile.read(path)\n",
    "        # Trailing 0s to achieve the same length as the longest instance\n",
    "        data_length = len(data)\n",
    "        new_data = np.concatenate((data, np.zeros(longest - data_length)))\n",
    "        # Compute the fft and add the instances to bundles to compute\n",
    "        fft = np.round(np.abs(rfft(new_data)), 4)\n",
    "        instance = np.concatenate([fft])\n",
    "        if bundle is None:\n",
    "            bundle = [instance]\n",
    "        elif len(bundle) < 150:\n",
    "            bundle = np.append(bundle, [instance], axis=0)\n",
    "        else:\n",
    "            bundles.append(bundle)\n",
    "            bundle = [instance]\n",
    "    bundles.append(bundle)  # Last remaining bundle\n",
    "    instances = np.concatenate(bundles, axis=0)\n",
    "\n",
    "    # Apply a StandardScalar and select n audio features\n",
    "    scalar = StandardScaler()\n",
    "    scalar.fit_transform(instances)\n",
    "    highest_var_indices = np.argpartition(scalar.var_, -n_audio_features)[-n_audio_features:]\n",
    "    instances = instances[:, highest_var_indices]\n",
    "    highest_var_features_names = freq_bins[highest_var_indices]\n",
    "    new_df = pd.DataFrame(data=instances, columns=highest_var_features_names)\n",
    "    new_df = new_df.sort_index(axis=1)\n",
    "\n",
    "    # Add the target and return\n",
    "    new_df[\"target\"] = df[\"key\"]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.0      36.6      36.7      38.0      38.2  38.300000000000004  \\\n",
      "0   3.0074   81.2963   83.7169  119.6888  115.8881            413.4768   \n",
      "1  13.6523  361.5547  119.7225  170.9554   84.0531            273.8909   \n",
      "2   7.1155   80.2869  169.7490  149.4092  132.8215            198.8544   \n",
      "3   2.0998  235.5117  161.2402  241.3578  243.2237             89.7297   \n",
      "4  16.2152  384.2739  174.5714   84.3117  137.9726            261.8213   \n",
      "\n",
      "       39.0      39.1      39.2       39.6  ...    466.0    523.0    523.1  \\\n",
      "0  136.8640  817.5328   86.4743   477.6116  ...  15.8853   1.5231   4.9432   \n",
      "1  175.9083  665.0791  588.2624    84.1962  ...   6.9459  26.9344   9.0805   \n",
      "2  150.5273  112.4005  335.4482   675.7621  ...   9.3406  18.8055   7.0021   \n",
      "3  640.7394  121.9373  396.3036  1138.3905  ...  26.2306   8.1640  26.6106   \n",
      "4  365.8102   96.3555  219.9515   211.2868  ...  39.9084   4.7010  50.1098   \n",
      "\n",
      "     523.4     524.4    524.5     554.2     554.4    1046.0       target  \n",
      "0   9.2590   20.5432   8.0715   23.6439   15.2647   34.3166   [E, major]  \n",
      "1  11.1132    6.9261  17.8961   25.1414   32.0681   11.3592   [E, major]  \n",
      "2  11.4548   11.9478  21.4284   23.2868   25.3144   10.5996   [E, major]  \n",
      "3  15.5312   17.1421  17.1426   28.0372   25.6042   18.4512   [E, major]  \n",
      "4  37.2416  113.0849  70.5330  144.2466  171.6769  106.9502  [C#, major]  \n",
      "\n",
      "[5 rows x 1001 columns]\n",
      "(9847, 1001)\n"
     ]
    }
   ],
   "source": [
    "def df_pipeline() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    From the original audio file and json pair dataset, \n",
    "    create the dataset from which to work \n",
    "    \"\"\"\n",
    "    df = pd.read_json(\"dataset/metadata.json\", lines=True)\n",
    "    df = features_from_audio(df, 1000)\n",
    "    return df\n",
    "\n",
    "df = df_pipeline()\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "df.to_json(\"data.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zachary\\AppData\\Local\\Temp\\ipykernel_16048\\271156794.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df = pd.read_json(\"data.json\", lines=True)\n",
      "C:\\Users\\Zachary\\AppData\\Local\\Temp\\ipykernel_16048\\271156794.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df = pd.read_json(\"data.json\", lines=True)\n",
      "C:\\Users\\Zachary\\AppData\\Local\\Temp\\ipykernel_16048\\271156794.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df = pd.read_json(\"data.json\", lines=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "[G, major]     763\n",
      "[C, major]     676\n",
      "[A, major]     670\n",
      "[D, major]     664\n",
      "[E, major]     602\n",
      "[F, major]     548\n",
      "[A, minor]     488\n",
      "[B, major]     425\n",
      "[C, minor]     366\n",
      "[G, minor]     344\n",
      "[D, minor]     337\n",
      "[C#, major]    305\n",
      "[F#, major]    304\n",
      "[Bb, major]    276\n",
      "[E, minor]     272\n",
      "[D#, major]    257\n",
      "[A#, major]    256\n",
      "[B, minor]     249\n",
      "[F, minor]     248\n",
      "[G#, major]    226\n",
      "[Ab, major]    191\n",
      "[F#, minor]    191\n",
      "[C#, minor]    188\n",
      "[Eb, major]    178\n",
      "[A#, minor]    155\n",
      "[D#, minor]    135\n",
      "[G#, minor]    134\n",
      "[Ab, minor]     89\n",
      "[Eb, minor]     76\n",
      "[Bb, minor]     72\n",
      "[Db, major]     66\n",
      "[Gb, major]     50\n",
      "[Gb, minor]     25\n",
      "[Db, minor]     21\n",
      "Name: count, dtype: int64\n",
      "note\n",
      "A     1158\n",
      "G     1107\n",
      "C     1042\n",
      "D     1001\n",
      "E      874\n",
      "F      796\n",
      "B      674\n",
      "F#     495\n",
      "C#     493\n",
      "A#     411\n",
      "D#     392\n",
      "G#     360\n",
      "Bb     348\n",
      "Ab     280\n",
      "Eb     254\n",
      "Db      87\n",
      "Gb      75\n",
      "Name: count, dtype: int64\n",
      "modality\n",
      "major    6457\n",
      "minor    3390\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"data.json\", lines=True)\n",
    "\n",
    "df[['note', 'modality']] = pd.DataFrame(df.target.tolist(), index=df.index)\n",
    "print(df[\"target\"].value_counts())\n",
    "print(df[\"note\"].value_counts())\n",
    "print(df[\"modality\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
