{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "The purpose of this notebook is to clean our original datasource (https://huggingface.co/datasets/amaai-lab/MusicBench) and extract features from the audio files in a way that builds a manageable dataset. Our full dataset was over 24GB, which presented a massive problem when trying to transmit the data, store it (too large for GitHub, Drive, etc.), or work with it. Operations on the data each took over an hour. Because of this, we have created this notebook which augments the original dataset, reducing its size (we were going to reduce the size in our original data cleaning pipeline anyway, we are just doing it up front to reduce the storage size).After removing a high volume of low confidence instances, the remaining instances go through a feature extraction process. First, this process builds a feature set which is the frequency profile of the given audio file (via a Fast Fourier Transformation). The result is a massive set with approximatly 80,000 features (freqency bins) for each instance. Our dataset is then approximatly 6GB, which is too large to run through machine learning algorithms on our computers. In order to reduce the size during this pre-processing phase, we are keeping the highest n (1000) variance features, assuming that these are the frequecy bins which best explain our data. The resulting smaller dataset is stored in train.json and test.json for efficient retrieval in main.ipynb. Thus, this notebook should be run ONCE after downloading the data from its source. The original dataset must be in the following directory format:\n",
    "\n",
    "\\dataset\\\n",
    "&ensp;&ensp;&ensp;\\data\\\n",
    "&ensp;&ensp;&ensp;\\data_aug2\\\n",
    "&ensp;&ensp;&ensp;MusicBench_train.json\\\n",
    "&ensp;&ensp;&ensp;MusicBench_test_A.json\n",
    "\n",
    "\n",
    "After running the following code, the original dataset will have been replaced by the dataset used in the project, and data.json will be the dataset to be used for algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_confidence_instances(old_metadata_path, new_metadata_path, threshold):\n",
    "    \"\"\"\n",
    "    For the given metadata json file, remove instances (record and file)\n",
    "    that are below the given threshold to reduce dataset size\n",
    "    \"\"\"\n",
    "    df = pd.read_json(old_metadata_path, lines=True)\n",
    "    df = df.drop_duplicates(subset=[\"location\"])\n",
    "    # Remove irrelavent features\n",
    "    df = df[[\"location\", \"key\", \"keyprob\"]]\n",
    "    df[\"keyprob\"] = df[\"keyprob\"].map(lambda x: x[0])\n",
    "    # Remove instances below the probability threshold\n",
    "    df_keep = df[df[\"keyprob\"] > threshold]\n",
    "    df_trash = df[df[\"keyprob\"] <= threshold]\n",
    "    # Delete all of the files associated with the removed instances\n",
    "    locations = df_trash[\"location\"].to_numpy()\n",
    "    not_found_count = 0\n",
    "    for loc in locations:\n",
    "        try:\n",
    "            pathlib.Path(\"dataset/\" + loc).unlink()\n",
    "        except FileNotFoundError:\n",
    "            print(\"Not Found: dataset/\" + loc)\n",
    "            not_found_count += 1\n",
    "    print(str(not_found_count) + \" WAV files not found for \" + old_metadata_path)\n",
    "    # Overwrite the old json metadata file\n",
    "    df_keep = df_keep[[\"location\", \"key\"]]\n",
    "    df_keep.to_json(new_metadata_path, orient=\"records\", lines=True)\n",
    "    pathlib.Path(old_metadata_path).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_analysis(locations, longest):\n",
    "    \"\"\"\n",
    "    Perform FFT analysis for a given set of audio files.\n",
    "    Return as a 2D numpy array of the instances\n",
    "    \"\"\"\n",
    "    # Calculate the features to populate a data array\n",
    "    bundles = []\n",
    "    bundle = None\n",
    "    for loc in locations:\n",
    "        path = \"dataset/\" + loc\n",
    "        samplerate, data = wavfile.read(path)\n",
    "        # Trailing 0s to achieve the same length as the longest instance\n",
    "        data_length = len(data)\n",
    "        new_data = np.concatenate((data, np.zeros(longest - data_length)))\n",
    "        # Compute the fft and add the instances to bundles to compute\n",
    "        fft = np.round(np.abs(rfft(new_data)), 4)\n",
    "        instance = np.concatenate([fft])\n",
    "        if bundle is None:\n",
    "            bundle = [instance]\n",
    "        elif len(bundle) < 150:\n",
    "            bundle = np.append(bundle, [instance], axis=0)\n",
    "        else:\n",
    "            bundles.append(bundle)\n",
    "            bundle = [instance]\n",
    "    bundles.append(bundle)  # Last remaining bundle\n",
    "    instances = np.concatenate(bundles, axis=0)\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_audio(train, test, n_audio_features) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    'Join' the existing dataframes with the audio files via\n",
    "    mapping to frequency features. Perform feature selection to \n",
    "    reduce the size of the resulting dataset.\n",
    "    \"\"\"\n",
    "    # Determine the size for all instances (largest number of samples)\n",
    "    longest = 0\n",
    "    rate = 0\n",
    "    train_locations = train[\"location\"].array.tolist()\n",
    "    test_locations = test[\"location\"].array.tolist()\n",
    "    locations = train_locations + test_locations\n",
    "    for loc in locations:\n",
    "        path = \"dataset/\" + loc\n",
    "        rate, data = wavfile.read(path)\n",
    "        length = len(data)\n",
    "        if length > longest:\n",
    "            longest = length\n",
    "\n",
    "    freq_bins = rfftfreq(longest, 1 / rate)\n",
    "\n",
    "    train_instances = fft_analysis(train_locations, longest)\n",
    "    test_instances = fft_analysis(test_locations, longest)\n",
    "\n",
    "    # Apply StandardScalars to the training and test data\n",
    "    train_scalar = StandardScaler()\n",
    "    train_scalar.fit_transform(train_instances)\n",
    "    test_scalar = StandardScaler()\n",
    "    test_scalar.fit_transform(test_instances)\n",
    "    # Select n audio features based on their variance in the training data\n",
    "    highest_var_indices = np.argpartition(train_scalar.var_, -n_audio_features)[-n_audio_features:]\n",
    "    train_instances = train_instances[:, highest_var_indices]\n",
    "    test_instances = test_instances[:, highest_var_indices]\n",
    "    highest_var_features_names = freq_bins[highest_var_indices]\n",
    "    # Place in DataFrames\n",
    "    train_df = pd.DataFrame(data=train_instances, columns=highest_var_features_names)\n",
    "    train_df = train_df.sort_index(axis=1)\n",
    "    test_df = pd.DataFrame(data=test_instances, columns=highest_var_features_names)\n",
    "    test_df = test_df.sort_index(axis=1)\n",
    "\n",
    "    # Add the target and return the dataframes\n",
    "    train_df[\"target\"] = train[\"key\"]\n",
    "    test_df[\"target\"] = test[\"key\"]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 WAV files not found for dataset/MusicBench_train.json\n",
      "0 WAV files not found for dataset/MusicBench_test_A.json\n",
      "[[4.29530000e+04 5.25835362e+04 8.07997420e+04 ... 7.79136400e+02\n",
      "  9.28917800e+02 1.07300000e+03]\n",
      " [2.10534000e+05 1.19505484e+05 2.01212752e+05 ... 1.59643620e+03\n",
      "  1.34979440e+03 1.59400000e+03]\n",
      " [5.80058000e+05 2.10840986e+05 3.15993333e+05 ... 4.26577450e+03\n",
      "  8.35656920e+03 1.01400000e+03]\n",
      " ...\n",
      " [5.42400000e+03 7.84261091e+04 3.96970382e+04 ... 4.15784700e+02\n",
      "  4.37823000e+02 3.64000000e+02]\n",
      " [1.75521000e+05 6.71018655e+04 2.07954143e+05 ... 8.95457100e+02\n",
      "  7.68177900e+02 6.89000000e+02]\n",
      " [8.66000000e+03 8.78701058e+04 4.80228784e+04 ... 3.17799600e+02\n",
      "  5.16470500e+02 4.90000000e+02]]\n",
      "       0.0      36.6      36.7      38.0      38.2  38.300000000000004  \\\n",
      "0   3.0074   81.2963   83.7169  119.6888  115.8881            413.4768   \n",
      "1  13.6523  361.5547  119.7225  170.9554   84.0531            273.8909   \n",
      "2   7.1155   80.2869  169.7490  149.4092  132.8215            198.8544   \n",
      "3   2.0998  235.5117  161.2402  241.3578  243.2237             89.7297   \n",
      "4  16.2152  384.2739  174.5714   84.3117  137.9726            261.8213   \n",
      "\n",
      "       39.0      39.1      39.2       39.6  ...    466.0    523.0    523.1  \\\n",
      "0  136.8640  817.5328   86.4743   477.6116  ...  15.8853   1.5231   4.9432   \n",
      "1  175.9083  665.0791  588.2624    84.1962  ...   6.9459  26.9344   9.0805   \n",
      "2  150.5273  112.4005  335.4482   675.7621  ...   9.3406  18.8055   7.0021   \n",
      "3  640.7394  121.9373  396.3036  1138.3905  ...  26.2306   8.1640  26.6106   \n",
      "4  365.8102   96.3555  219.9515   211.2868  ...  39.9084   4.7010  50.1098   \n",
      "\n",
      "     523.4     524.4    524.5     554.2     554.4    1046.0       target  \n",
      "0   9.2590   20.5432   8.0715   23.6439   15.2647   34.3166   [E, major]  \n",
      "1  11.1132    6.9261  17.8961   25.1414   32.0681   11.3592   [E, major]  \n",
      "2  11.4548   11.9478  21.4284   23.2868   25.3144   10.5996   [E, major]  \n",
      "3  15.5312   17.1421  17.1426   28.0372   25.6042   18.4512   [E, major]  \n",
      "4  37.2416  113.0849  70.5330  144.2466  171.6769  106.9502  [C#, major]  \n",
      "\n",
      "[5 rows x 1001 columns]\n",
      "(9847, 1001)\n",
      "        0.0          36.6          36.7          38.0          38.2  \\\n",
      "0   42953.0  3.177310e+05  7.162439e+05  6.183831e+05  4.687232e+05   \n",
      "1  210534.0  2.755219e+06  5.760713e+06  3.012455e+06  7.027697e+06   \n",
      "2  580058.0  2.267626e+05  3.962619e+05  7.149067e+05  7.282511e+05   \n",
      "3  294866.0  1.177008e+05  1.405851e+05  4.735022e+05  2.273087e+05   \n",
      "4  209925.0  9.666467e+05  3.509573e+06  5.416213e+06  2.633137e+06   \n",
      "\n",
      "   38.300000000000004          39.0          39.1          39.2          39.6  \\\n",
      "0        5.708468e+05  4.959344e+05  1.723302e+05  5.674570e+05  1.226242e+06   \n",
      "1        6.107353e+06  2.502087e+06  4.772452e+06  4.192839e+06  3.031467e+06   \n",
      "2        7.879141e+05  8.894713e+05  9.402851e+05  5.270641e+05  4.063166e+05   \n",
      "3        2.784361e+05  9.851231e+04  2.442480e+05  2.850396e+05  1.732757e+05   \n",
      "4        3.468122e+06  1.656417e+06  6.437347e+06  1.693363e+06  3.443143e+06   \n",
      "\n",
      "   ...         466.0         523.0         523.1         523.4         524.4  \\\n",
      "0  ...  2.658518e+06  6.871011e+05  4.688614e+05  1.073632e+06  1.511854e+05   \n",
      "1  ...  2.321413e+06  2.241338e+06  1.416837e+06  1.119808e+06  1.057551e+06   \n",
      "2  ...  2.064484e+06  5.894490e+06  1.037315e+07  9.294843e+06  6.309327e+06   \n",
      "3  ...  5.982131e+05  5.134673e+04  7.452115e+04  1.666723e+05  3.162169e+05   \n",
      "4  ...  1.691764e+06  1.023994e+07  9.179571e+06  7.589767e+06  1.468757e+07   \n",
      "\n",
      "          524.5         554.2         554.4        1046.0       target  \n",
      "0  8.207045e+05  5.836288e+05  2.402331e+05  1.909614e+06  [Bb, major]  \n",
      "1  2.439462e+06  1.063194e+06  1.267584e+06  1.121252e+06  [Ab, minor]  \n",
      "2  1.041351e+07  2.022372e+06  1.087775e+07  1.685454e+06   [B, major]  \n",
      "3  2.543665e+05  3.163680e+05  3.206237e+05  3.771183e+05   [D, minor]  \n",
      "4  1.240105e+07  1.136316e+06  3.722263e+06  6.491401e+06   [A, minor]  \n",
      "\n",
      "[5 rows x 1001 columns]\n",
      "(206, 1001)\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = 1000\n",
    "\n",
    "drop_low_confidence_instances(old_metadata_path=\"dataset/MusicBench_train.json\",\n",
    "                              new_metadata_path=\"dataset/metadata_train.json\",\n",
    "                              threshold=0.88)\n",
    "drop_low_confidence_instances(old_metadata_path=\"dataset/MusicBench_test_A.json\",\n",
    "                              new_metadata_path=\"dataset/metadata_test.json\",\n",
    "                              threshold=0.80)\n",
    "\n",
    "train_df = pd.read_json(\"dataset/metadata_train.json\", lines=True)\n",
    "test_df = pd.read_json(\"dataset/metadata_test.json\", lines=True)\n",
    "\n",
    "train_df, test_df = features_from_audio(train_df, test_df, N_FEATURES)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.shape)\n",
    "train_df.to_json(\"train.json\", orient=\"records\", lines=True)\n",
    "print(test_df.head())\n",
    "print(test_df.shape)\n",
    "test_df.to_json(\"test.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
