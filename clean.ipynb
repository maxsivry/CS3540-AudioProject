{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "The purpose of this notebook is to clean our original datasource (https://huggingface.co/datasets/amaai-lab/MusicBench) and extract features from the audio files in a way that builds a manageable dataset. Our full dataset was over 24GB, which presented a massive problem when trying to transmit the data, store it (too large for GitHub, Drive, etc.), or work with it. Operations on the data each took over an hour. Because of this, we have created this notebook which augments the original dataset, reducing its size (we were going to reduce the size in our original data cleaning pipeline anyway, we are just doing it up front to reduce the storage size).After removing a high volume of low confidence instances, the remaining instances go through a feature extraction process. First, this process builds a feature set which is the frequency profile of the given audio file (via a Fast Fourier Transformation). The result is a massive set with approximatly 80,000 features (freqency bins) for each instance. Our dataset is then approximatly 6GB, which is too large to run through machine learning algorithms on our computers. In order to reduce the size during this pre-processing phase, we are keeping the highest n (1000) variance features, assuming that these are the frequecy bins which best explain our data. The resulting smaller dataset is stored in train.json and test.json for efficient retrieval in main.ipynb. Thus, this notebook should be run ONCE after downloading the data from its source. The original dataset must be in the following directory format:\n",
    "\n",
    "\\dataset\\\n",
    "&ensp;&ensp;&ensp;\\data\\\n",
    "&ensp;&ensp;&ensp;\\data_aug2\\\n",
    "&ensp;&ensp;&ensp;MusicBench_train.json\\\n",
    "&ensp;&ensp;&ensp;MusicBench_test_A.json\n",
    "\n",
    "\n",
    "After running the following code, the original dataset will have been replaced by the dataset used in the project, and data.json will be the dataset to be used for algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_confidence_instances(old_metadata_path, new_metadata_path, threshold):\n",
    "    \"\"\"\n",
    "    For the given metadata json file, remove instances (record and file)\n",
    "    that are below the given threshold to reduce dataset size\n",
    "    \"\"\"\n",
    "    df = pd.read_json(old_metadata_path, lines=True)\n",
    "    df = df.drop_duplicates(subset=[\"location\"])\n",
    "    # Remove irrelavent features\n",
    "    df = df[[\"location\", \"key\", \"keyprob\"]]\n",
    "    df[\"keyprob\"] = df[\"keyprob\"].map(lambda x: x[0])\n",
    "    # Remove instances below the probability threshold\n",
    "    df_keep = df[df[\"keyprob\"] > threshold]\n",
    "    df_trash = df[df[\"keyprob\"] <= threshold]\n",
    "    # Delete all of the files associated with the removed instances\n",
    "    locations = df_trash[\"location\"].to_numpy()\n",
    "    not_found_count = 0\n",
    "    for loc in locations:\n",
    "        try:\n",
    "            #pathlib.Path(\"dataset/\" + loc).unlink()\n",
    "            pass\n",
    "        except FileNotFoundError:\n",
    "            print(\"Not Found: dataset/\" + loc)\n",
    "            not_found_count += 1\n",
    "    print(str(not_found_count) + \" WAV files not found for \" + old_metadata_path)\n",
    "    # Overwrite the old json metadata file\n",
    "    df_keep = df_keep[[\"location\", \"key\"]]\n",
    "    df_keep.to_json(new_metadata_path, orient=\"records\", lines=True)\n",
    "    pathlib.Path(old_metadata_path).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_analysis(locations, longest):\n",
    "    \"\"\"\n",
    "    Perform FFT analysis for a given set of audio files.\n",
    "    Return as a 2D numpy array of the instances\n",
    "    \"\"\"\n",
    "    # Calculate the features to populate a data array\n",
    "    bundles = []\n",
    "    bundle = None\n",
    "    for loc in locations:\n",
    "        path = \"dataset/\" + loc\n",
    "        samplerate, data = wavfile.read(path)\n",
    "        # Trailing 0s to achieve the same length as the longest instance\n",
    "        data_length = len(data)\n",
    "        new_data = np.concatenate((data, np.zeros(longest - data_length)))\n",
    "        # Compute the fft and add the instances to bundles to compute\n",
    "        fft = np.round(np.abs(rfft(new_data)), 4)\n",
    "        instance = np.concatenate([fft])\n",
    "        if bundle is None:\n",
    "            bundle = [instance]\n",
    "        elif len(bundle) < 150:\n",
    "            bundle = np.append(bundle, [instance], axis=0)\n",
    "        else:\n",
    "            bundles.append(bundle)\n",
    "            bundle = [instance]\n",
    "    bundles.append(bundle)  # Last remaining bundle\n",
    "    instances = np.concatenate(bundles, axis=0)\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_audio(train, test, n_audio_features) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    'Join' the existing dataframes with the audio files via\n",
    "    mapping to frequency features. Perform feature selection to \n",
    "    reduce the size of the resulting dataset.\n",
    "    \"\"\"\n",
    "    # Determine the size for all instances (largest number of samples)\n",
    "    longest = 0\n",
    "    rate = 0\n",
    "    train_locations = train[\"location\"].array.tolist()\n",
    "    test_locations = test[\"location\"].array.tolist()\n",
    "    locations = train_locations + test_locations\n",
    "    for loc in locations:\n",
    "        path = \"dataset/\" + loc\n",
    "        rate, data = wavfile.read(path)\n",
    "        length = len(data)\n",
    "        if length > longest:\n",
    "            longest = length\n",
    "\n",
    "    freq_bins = rfftfreq(longest, 1 / rate)\n",
    "\n",
    "    train_instances = fft_analysis(train_locations, longest)\n",
    "    test_instances = fft_analysis(test_locations, longest)\n",
    "\n",
    "    # Apply StandardScalars to the training and test data\n",
    "    train_scalar = StandardScaler()\n",
    "    train_scalar.fit_transform(train_instances)\n",
    "    test_scalar = StandardScaler()\n",
    "    test_scalar.fit_transform(test_instances)\n",
    "    # Select n audio features based on their variance in the training data\n",
    "    highest_var_indices = np.argpartition(train_scalar.var_, -n_audio_features)[-n_audio_features:]\n",
    "    train_instances = train_instances[:, highest_var_indices]\n",
    "    test_instances = test_instances[:, highest_var_indices]\n",
    "    highest_var_features_names = freq_bins[highest_var_indices]\n",
    "    # Place in DataFrames\n",
    "    train_df = pd.DataFrame(data=train_instances, columns=highest_var_features_names)\n",
    "    train_df = train_df.sort_index(axis=1)\n",
    "    test_df = pd.DataFrame(data=test_instances, columns=highest_var_features_names)\n",
    "    test_df = test_df.sort_index(axis=1)\n",
    "\n",
    "    # Add the target and return the dataframes\n",
    "    train_df[\"target\"] = train[\"key\"]\n",
    "    test_df[\"target\"] = test[\"key\"]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 WAV files not found for dataset/MusicBench_train.json\n",
      "0 WAV files not found for dataset/MusicBench_test_A.json\n",
      "       0.0      21.0     21.6      23.3      27.3  27.400000000000002  \\\n",
      "0   3.0074   66.1481  18.9519   61.7838   29.3859             49.9619   \n",
      "1  13.6523    9.5553  73.5916   70.8303   17.4072            136.9175   \n",
      "2   7.1155   20.6097  32.4317   93.8293  135.5899            118.9356   \n",
      "3   2.0998   54.2579  67.8662   22.9191  222.2046            115.5188   \n",
      "4  16.2152  122.5829  91.6652  377.8725  148.3863             70.6888   \n",
      "\n",
      "       27.5  28.900000000000002      29.1  29.200000000000003  ...   1174.9  \\\n",
      "0   44.3474             43.1442  155.3489             69.4313  ...   3.0022   \n",
      "1  112.4078            110.2259   48.8999             97.4619  ...   7.4835   \n",
      "2  130.3074             88.1421   65.4813             51.5041  ...  12.0219   \n",
      "3   24.8653            156.0586  371.9792             64.8751  ...   5.5838   \n",
      "4  207.7440             27.3765  218.5836            146.0195  ...   1.1833   \n",
      "\n",
      "   1175.0  1175.1000000000001   1175.2  1175.3  1175.4  1176.0  1179.7  \\\n",
      "0  1.8245             10.2300   4.2915  7.6392  4.4576  5.2488  8.6626   \n",
      "1  7.3839             10.3402  12.0310  7.4713  8.0679  3.9016  1.8872   \n",
      "2  5.2784              7.8041   4.5978  1.2935  1.7228  0.4162  1.6418   \n",
      "3  9.3884              2.3016   2.1491  8.9235  8.7954  4.6561  4.0255   \n",
      "4  5.3357              5.5381   2.8905  7.0133  1.8103  5.0214  6.3823   \n",
      "\n",
      "   1179.9       target  \n",
      "0  8.7103   [E, major]  \n",
      "1  6.0612   [E, major]  \n",
      "2  4.1964   [E, major]  \n",
      "3  4.9221   [E, major]  \n",
      "4  6.7298  [C#, major]  \n",
      "\n",
      "[5 rows x 5001 columns]\n",
      "(9847, 5001)\n",
      "        0.0          21.0          21.6          23.3          27.3  \\\n",
      "0   42953.0  1.709812e+05  7.740293e+04  1.610568e+05  1.823593e+05   \n",
      "1  210534.0  7.430664e+06  8.513174e+06  4.963349e+06  6.861083e+06   \n",
      "2  580058.0  1.295052e+06  1.781498e+06  1.042412e+06  9.213877e+05   \n",
      "3  294866.0  1.359246e+05  2.191063e+05  3.327040e+05  2.501218e+05   \n",
      "4  209925.0  1.831214e+06  3.939340e+05  1.270487e+06  1.483926e+06   \n",
      "\n",
      "   27.400000000000002          27.5  28.900000000000002          29.1  \\\n",
      "0        2.041305e+05  1.553069e+05        1.648655e+05  2.250257e+05   \n",
      "1        4.035599e+06  1.791982e+06        6.716239e+06  2.027559e+06   \n",
      "2        5.730518e+05  6.540001e+05        1.401534e+06  7.726469e+05   \n",
      "3        3.711633e+05  2.578964e+05        2.476175e+05  1.180911e+05   \n",
      "4        5.430231e+05  1.618335e+06        2.840812e+06  3.740331e+06   \n",
      "\n",
      "   29.200000000000003  ...        1174.9        1175.0  1175.1000000000001  \\\n",
      "0        3.918388e+04  ...  5.777672e+05  2.226609e+05        7.798114e+05   \n",
      "1        6.672297e+06  ...  2.290167e+05  5.658647e+05        1.351803e+06   \n",
      "2        8.862915e+05  ...  1.265257e+06  2.255889e+06        1.065882e+06   \n",
      "3        2.089778e+05  ...  7.034851e+06  5.749858e+06        4.181971e+06   \n",
      "4        1.706440e+06  ...  5.171391e+06  3.100427e+06        6.237851e+06   \n",
      "\n",
      "         1175.2        1175.3        1175.4        1176.0        1179.7  \\\n",
      "0  4.812028e+05  1.756044e+05  8.520478e+05  3.587613e+05  1.037174e+06   \n",
      "1  6.305739e+05  2.406629e+05  3.529961e+05  1.270260e+06  7.084158e+05   \n",
      "2  1.360337e+06  5.426118e+05  2.609300e+05  1.141503e+06  1.344331e+06   \n",
      "3  3.312564e+06  3.309469e+06  1.627244e+06  7.250057e+06  5.876983e+06   \n",
      "4  3.753115e+06  6.129353e+06  1.058542e+06  1.519210e+06  3.034788e+06   \n",
      "\n",
      "         1179.9       target  \n",
      "0  8.826256e+05  [Bb, major]  \n",
      "1  7.676486e+05  [Ab, minor]  \n",
      "2  1.021052e+06   [B, major]  \n",
      "3  1.636371e+06   [D, minor]  \n",
      "4  1.296190e+06   [A, minor]  \n",
      "\n",
      "[5 rows x 5001 columns]\n",
      "(206, 5001)\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = 5000\n",
    "\n",
    "drop_low_confidence_instances(old_metadata_path=\"dataset/MusicBench_train.json\",\n",
    "                              new_metadata_path=\"dataset/metadata_train.json\",\n",
    "                              threshold=0.88)\n",
    "drop_low_confidence_instances(old_metadata_path=\"dataset/MusicBench_test_A.json\",\n",
    "                              new_metadata_path=\"dataset/metadata_test.json\",\n",
    "                              threshold=0.85)\n",
    "\n",
    "train_df = pd.read_json(\"dataset/metadata_train.json\", lines=True)\n",
    "test_df = pd.read_json(\"dataset/metadata_test.json\", lines=True)\n",
    "\n",
    "train_df, test_df = features_from_audio(train_df, test_df, N_FEATURES)\n",
    "\n",
    "# The original test data was too small. Pull from the training data to add to it\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df[:, :-1], train_df[\"target\"], test_size=0.1, random_state=42)\n",
    "train_df = pd.DataFrame(data=[X_train, y_train])\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.shape)\n",
    "train_df.to_json(\"train.json\", orient=\"records\", lines=True)\n",
    "print(test_df.head())\n",
    "print(test_df.shape)\n",
    "test_df.to_json(\"test.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
